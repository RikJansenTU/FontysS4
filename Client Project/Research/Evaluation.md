### General Research Evaluation
While I definitely expected the AI generated imagery to have a positive effect on ideation, I didn't expect it to be quite so pronounced. The drawings people made proved quite a good way to quantify something as vague as 'creativity', but being able to see what elements they added to their second concept, and how often they directly corresponded to elements in the AI images, really helped pin down which images served as the best inspiration.

The most difficult part of setting up this user research was knowing what subject to pick for the concepts. I first wanted to be more specific, and ask people to create a christmas-themed advertising poster for an electric car, which I hoped would deliver more quantifiable results, but in the end we decided to go with something simpler, so as not to overwhelm people. I do think this worked out, since for some subjects merely having to draw something in a limited time was already a barrier of entry, and while the concept was simple there was still plenty that could be added.

![crayon christmas car](https://user-images.githubusercontent.com/9715331/212675114-0a8ea02f-7771-4140-b42a-17a7f1d48956.jpg)

_One of the generated images for my christmas electric car advertisement concept_


### Effect on Future Prototypes
Determining what images had the most effect was very important; inspiring people can be a pretty daunting task, and the more handholds we get in knowing how to do it the better. When Greenhouse employees use our room to, for example, ask for inspiration on chairs, it won't be very useful to just show them slightly weird pictures of chairs. Inspiration often springs from combining multiple ideas, and our room has the potential to provide those ideas. So, based on the research results, there are two major additions I want to make to the prototype:

1. More related imagery. This is something that might prove difficult, considering you can't just ask an AI to create pictures closely related to a subject, but seeing the research results it's something well worth pursuing. There are however synonym and anthonym libraries, and we use [this API](https://api-ninjas.com/api/thesaurus) to find them, and use the results to adjust our prompts. This way, there will be a larger variety in images, without them being completely unrelated, which will hopefully serve as better inspiration.
2. Stylistic changes. This is something that is easier to do, and I have created some alternate versions of our prototype that utilise these changes. There are some [great guides on how to get interesting stylistic results with DALL-E](https://docs.google.com/document/d/11WlzjBT0xRpQhP9tFMtxzd0q6ANIdHPUBkMV-YB043U/edit#), and using those I experimented with styles, seeing which one created the most interesting and inspiring results. Eventually I narrowed the list down to a few I thought worked best, and made it so every once in a while, the image will be generated in a different style. Not only will this result in greater variation in results, but also (hopefully) serve as stylistic inspiration, something the research proved is possible.
